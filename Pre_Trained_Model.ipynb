{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Pre-Trained Model.ipynb",
      "provenance": [],
      "machine_shape": "hm"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "llRHsPbl-kI2"
      },
      "source": [
        "#!pip install wandb\n",
        "#import wandb\n",
        "#wandb.init()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8oEo4-w47wBb"
      },
      "source": [
        "import os\n",
        "import cv2\n",
        "import math\n",
        "import random\n",
        "import numpy as np\n",
        "import datetime as dt\n",
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "%matplotlib inline\n",
        "\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "from tensorflow.keras.layers import *\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.utils import to_categorical\n",
        "from tensorflow.keras.callbacks import EarlyStopping\n",
        "from tensorflow.keras.utils import plot_model\n",
        "\n",
        "from keras.applications.vgg16 import VGG16\n",
        "from keras.applications.vgg16 import preprocess_input"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rVejMMKZM0ig"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/gdrive')\n",
        "%cd /gdrive"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Nf8ynhrLM5ie"
      },
      "source": [
        "%cd 'My Drive'\n",
        "\n",
        "%cd 'Action Recognition'"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Yrtnc8qgMFft"
      },
      "source": [
        "image_height, image_width = 64, 64\n",
        "images_per_class = 8000\n",
        "dataset_directory = \"hmdb51\"\n",
        "classes_list = [\"pullup\", \"punch\", \"dive\", \"fencing\", \"ride_bike\", \"golf\"]\n",
        "model_output_size = len(classes_list)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3Weq19RqMK6a"
      },
      "source": [
        "def frames_extraction(video_path):\n",
        "    frames_list = []\n",
        "    video_reader = cv2.VideoCapture(video_path)\n",
        "\n",
        "  \n",
        "    while True:\n",
        "        success, frame = video_reader.read() \n",
        "        if not success:\n",
        "            print(\"Defected frame\")\n",
        "            break\n",
        "        resized_frame = cv2.resize(frame, (image_height, image_width))\n",
        "        normalized_frame = preprocess_input(resized_frame)\n",
        "        frames_list.append(normalized_frame)\n",
        "    \n",
        "    video_reader.release()\n",
        "\n",
        "    return frames_list"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Wg2u7D-IMNZJ"
      },
      "source": [
        "def create_dataset():\n",
        "\n",
        "    \n",
        "    temp_features = [] \n",
        "    features = []\n",
        "    labels = []\n",
        "    \n",
        "  \n",
        "    for class_index, class_name in enumerate(classes_list):\n",
        "        print(f'Extracting Data of Class: {class_name}')\n",
        "        \n",
        "       \n",
        "        files_list = os.listdir(os.path.join(dataset_directory, class_name))\n",
        "\n",
        "      \n",
        "        for file_name in files_list:\n",
        "            video_file_path = os.path.join(dataset_directory, class_name, file_name)\n",
        "            frames = frames_extraction(video_file_path)\n",
        "            temp_features.extend(frames)\n",
        "        features.extend(random.sample(temp_features, images_per_class))\n",
        "        labels.extend([class_index] * images_per_class)\n",
        "        temp_features.clear()\n",
        "\n",
        "    features = np.asarray(features)\n",
        "    labels = np.array(labels)  \n",
        "\n",
        "    return features, labels"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mDCZbL0mMrkw"
      },
      "source": [
        "features, labels = create_dataset()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Qi3rJEoTP0xh"
      },
      "source": [
        "seed_constant = 23\n",
        "np.random.seed(seed_constant)\n",
        "random.seed(seed_constant)\n",
        "tf.random.set_seed(seed_constant)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1PPM4IhVO6PV"
      },
      "source": [
        "print (features.shape)\n",
        "print (labels.shape)\n",
        "\n",
        "one_hot_encoded_labels = to_categorical(labels)\n",
        "\n",
        "features_train, features_test, labels_train, labels_test = train_test_split(features, one_hot_encoded_labels, test_size = 0.2, shuffle = True, random_state = seed_constant)\n",
        "\n",
        "print (features_train.shape)\n",
        "print (labels_train.shape)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kxCfgxjPQB4q"
      },
      "source": [
        "print (labels_train)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nKv8N4xW8Ovx"
      },
      "source": [
        "# load model\n",
        "base_model = Sequential()\n",
        "base_model.add(VGG16(input_shape=(64,64,3), weights='imagenet', include_top=False, pooling='avg'))\n",
        "base_model.add(Dense(288, activation = 'relu'))\n",
        "base_model.add(Dense(288, activation = 'relu'))\n",
        "base_model.add(Dense(6, activation='softmax'))\n",
        "# summarize the model\n",
        "\n",
        "base_model.layers[0].trainable = False\n",
        "\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-38MTuU0-z58"
      },
      "source": [
        "base_model.compile(optimizer='sgd',loss='categorical_crossentropy',metrics=['accuracy'])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SDH6lDjvPNUj"
      },
      "source": [
        "plot_model(base_model,show_shapes = True, show_layer_names = True)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_0JOoIulPWc5"
      },
      "source": [
        "# Adding Early Stopping Callback\n",
        "early_stopping_callback = EarlyStopping(monitor = 'val_loss', patience = 10, mode = 'min', restore_best_weights = True)\n",
        "\n",
        "# Start Training\n",
        "model_training_history = base_model.fit(x = features_train, y = labels_train, epochs = 40, batch_size = 16 , shuffle = True, validation_split = 0.2, callbacks = [early_stopping_callback])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9JxQ_eNcWDV_"
      },
      "source": [
        "model_evaluation_history = base_model.evaluate(features_test, labels_test)\n",
        "\n",
        "from sklearn.metrics import classification_report\n",
        "\n",
        "y_pred = base_model.predict(features_test, batch_size=4, verbose=1)\n",
        "y_pred_bool = np.argmax(y_pred, axis=1)\n",
        "\n",
        "l_test=np.argmax(labels_test, axis=1)\n",
        "\n",
        "print(classification_report(l_test, y_pred_bool))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HneskllIWW1o"
      },
      "source": [
        "from sklearn.metrics import confusion_matrix\n",
        "cm = confusion_matrix(l_test, y_pred_bool)\n",
        "\n",
        "print (cm)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Tz2uKctMWgOA"
      },
      "source": [
        "def plot_metric(metric_name_1, metric_name_2, plot_name):\n",
        "  # Get Metric values using metric names as identifiers\n",
        "  metric_value_1 = model_training_history.history[metric_name_1]\n",
        "  metric_value_2 = model_training_history.history[metric_name_2]\n",
        "\n",
        "  # Constructing a range object which will be used as time \n",
        "  epochs = range(len(metric_value_1))\n",
        "  \n",
        "  # Plotting the Graph\n",
        "  plt.plot(epochs, metric_value_1, 'blue', label = metric_name_1)\n",
        "  plt.plot(epochs, metric_value_2, 'red', label = metric_name_2)\n",
        "  \n",
        "  # Adding title to the plot\n",
        "  plt.title(str(plot_name))\n",
        "\n",
        "  # Adding legend to the plot\n",
        "  plt.legend()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sKL7vCcGWr0D"
      },
      "source": [
        "plot_metric('loss', 'val_loss', 'Total Loss vs Total Validation Loss')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dH1VK0KvWtvD"
      },
      "source": [
        "plot_metric('accuracy', 'val_accuracy', 'Total Accuracy vs Total Validation Accuracy')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bMuONYTHRrsA"
      },
      "source": [
        "from collections import Counter\n",
        "\n",
        "def get_first_mode(a):\n",
        "    c = Counter(a)  \n",
        "    mode_count = max(c.values())\n",
        "    mode = {key for key, count in c.items() if count == mode_count}\n",
        "    first_mode = next(x for x in a if x in mode)\n",
        "    return first_mode"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1B9e7Ln0Rvfw"
      },
      "source": [
        "\n",
        "\n",
        "def frames_extraction2(video_path):\n",
        "    frames_list = []\n",
        "    \n",
        "    vidObj = cv2.VideoCapture(video_path)\n",
        "    skip_frames=30\n",
        "  \n",
        "\n",
        "\n",
        "    # Used as counter variable \n",
        "    count = 0\n",
        " \n",
        "    while True: \n",
        "         \n",
        "        success, image = vidObj.read() \n",
        "\n",
        "        if success == False:\n",
        "          print(\"Defected frame\")\n",
        "          break\n",
        "\n",
        "        if count == 0:\n",
        "            image = cv2.resize(image, (image_height, image_width))\n",
        "            normalized_image = preprocess_input(image)\n",
        "            frames_list.append(normalized_image)\n",
        "        \n",
        "        else:\n",
        "          if count % 25 == 0:\n",
        "            image = cv2.resize(image, (image_height, image_width))\n",
        "            normalized_image = preprocess_input(image)\n",
        "            frames_list.append(normalized_image)\n",
        "        \n",
        "        count += 1\n",
        "            \n",
        "       \n",
        "            \n",
        "    return frames_list"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LVUuImAbXSAV"
      },
      "source": [
        "#Evaluating a different dataset\n",
        "\n",
        "from tqdm import tqdm\n",
        "from statistics import mode\n",
        "\n",
        "\n",
        "predict = []\n",
        "actual = []\n",
        "dataset_directory2=\"UCF50\"\n",
        "\n",
        "temp_features = [] \n",
        "features = []\n",
        "labels = []\n",
        "\n",
        "cc=0\n",
        "\n",
        "for class_index, class_name in enumerate(classes_list):\n",
        "    print(f'Extracting Data of Class: {class_name}')\n",
        "    \n",
        "    files_list = os.listdir(os.path.join(dataset_directory2, class_name))\n",
        "\n",
        "    for file_name in files_list:\n",
        "\n",
        "        video_file_path = os.path.join(dataset_directory2, class_name, file_name)\n",
        "\n",
        "        frames = frames_extraction2(video_file_path)\n",
        "\n",
        "        temppred=[]\n",
        "\n",
        "        for i in frames:\n",
        "          temppred.append(base_model.predict_classes(np.expand_dims(i, axis = 0))[0])\n",
        "        \n",
        "        print (temppred)\n",
        "        print (\"mode\", get_first_mode(temppred), cc)\n",
        "        cc+=1\n",
        "        predict.append(get_first_mode(temppred))\n",
        "        actual.append(class_index)\n",
        "\n",
        "\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7lKzKbNLXZ_-"
      },
      "source": [
        "print(classification_report(actual, predict))\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pBWHUjr6XlvY"
      },
      "source": [
        "print(confusion_matrix(actual, predict))"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}