{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "name": "CONV2D Action Recognition.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "machine_shape": "hm"
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "9s39yElYhs4N"
      },
      "source": [
        "#!pip install wandb\n",
        "#import wandb\n",
        "#wandb.init()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6BbJWRXlJ-wd"
      },
      "source": [
        "import os         #Import required modules\n",
        "import cv2\n",
        "import math\n",
        "import random\n",
        "import numpy as np\n",
        "import datetime as dt\n",
        "import tensorflow as tf\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "%matplotlib inline\n",
        "from sklearn.model_selection import train_test_split\n",
        "from tensorflow.keras.layers import *\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.utils import to_categorical\n",
        "from tensorflow.keras.callbacks import EarlyStopping\n",
        "from tensorflow.keras.utils import plot_model\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sgXc9OdQKYLE"
      },
      "source": [
        "seed_constant = 23   #Initialize random number generator\n",
        "np.random.seed(seed_constant)\n",
        "random.seed(seed_constant)\n",
        "tf.random.set_seed(seed_constant)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "as2q_7uKKcul"
      },
      "source": [
        "from google.colab import drive    \n",
        "drive.mount('/gdrive')\n",
        "%cd /gdrive                      "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kttPfE9yKzmI"
      },
      "source": [
        "%cd 'My Drive/'                   \n",
        "\n",
        "%cd 'Action Recognition'\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bE7MFdDmLCbT"
      },
      "source": [
        "%ls"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VktUVQiBeCrj"
      },
      "source": [
        "#Constants\n",
        "\n",
        "datasetName= 'hmdb51'              #Chosen Dataset"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aUvcHinhOwuP"
      },
      "source": [
        "image_height, image_width = 64, 64        #Set pixel values\n",
        "images_per_class = 8000               #Set number of frames from each video class\n",
        "dataset_directory = \"hmdb51\"              #Set dataset name\n",
        "classes_list = [\"pullup\", \"punch\", \"dive\", \"fencing\", \"ride_bike\", \"golf\"]   #Choose classes from dataset\n",
        "model_output_size = len(classes_list)     #test\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cxnVgT1BPmGU"
      },
      "source": [
        "def frames_extraction(video_path):  #helper function to extract frames from videos\n",
        "    frames_list = []                #empty list for frames\n",
        "    video_reader = cv2.VideoCapture(video_path) #Read frames from video\n",
        "    while True:     #Iterate through frames\n",
        "        success, frame = video_reader.read() #Whilst frames are available\n",
        "        if not success:\n",
        "            break\n",
        "        resized_frame = cv2.resize(frame, (image_height, image_width))    #Resize to pre-defined pixel values\n",
        "        normalized_frame = resized_frame / 255                            #Normalize frames to range 0-1\n",
        "        frames_list.append(normalized_frame)                              #Add to frame list for this video\n",
        "    video_reader.release()                                                #Close and release contents\n",
        "    return frames_list                                                     #Return frames from this video"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pu-vIhjfPyhk"
      },
      "source": [
        "def create_dataset():    #Create dataset function\n",
        "    temp_features = [] #empty list to hold each videos frames\n",
        "    features = []  #final list of frames will be in this list\n",
        "    labels = []  #Final list of labels will be in this list\n",
        "\n",
        "    for class_index, class_name in enumerate(classes_list):  #Iterate through chosen classes\n",
        "        print(f'Extracting Data of Class: {class_name}')        \n",
        "        files_list = os.listdir(os.path.join(dataset_directory, class_name)) #Got to class folder and get video list\n",
        "        for file_name in files_list:\n",
        "            video_file_path = os.path.join(dataset_directory, class_name, file_name)\n",
        "            frames = frames_extraction(video_file_path)   #Extract frames for current video\n",
        "            temp_features.extend(frames)      #Add to temp frames list\n",
        "\n",
        "        features.extend(random.sample(temp_features, images_per_class))       #Choose 8000 random frames from current class (all videos in class)\n",
        "        labels.extend([class_index] * images_per_class)                         #Assign 8000 labels correctly\n",
        "        temp_features.clear()\n",
        "\n",
        "    features = np.asarray(features)   #Convert both to numpy array\n",
        "    labels = np.array(labels)  \n",
        "    return features, labels"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ditWFy33QCfw"
      },
      "source": [
        "features, labels = create_dataset()   #Fetch data"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Q1Hpo22S7mIh"
      },
      "source": [
        "print (features.shape)\n",
        "print (labels.shape)\n",
        "#print (features)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EobZUwegRvCL"
      },
      "source": [
        "one_hot_encoded_labels = to_categorical(labels) #convert labels into one-hot-encoded vectors"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AJtwnA1_R0cs"
      },
      "source": [
        "features_train, features_test, labels_train, labels_test = train_test_split(features, one_hot_encoded_labels, test_size = 0.2, shuffle = True, random_state = seed_constant)  #Convert to test and train sets"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qyo-l4nzR-F5"
      },
      "source": [
        "def create_model():  #Create NN\n",
        "    model = Sequential() #Keras sequential model\n",
        "\n",
        "    model.add(Conv2D(filters = 64, kernel_size = (3, 3), activation = 'relu', input_shape = (image_height, image_width, 3)))   #Add various layers\n",
        "    model.add(Conv2D(filters = 64, kernel_size = (3, 3), activation = 'relu'))\n",
        "    model.add(Conv2D(filters = 64, kernel_size = (3, 3), activation = 'relu'))\n",
        "    model.add(Conv2D(filters = 64, kernel_size = (3, 3), activation = 'relu'))\n",
        "    model.add(Conv2D(filters = 64, kernel_size = (3, 3), activation = 'relu'))\n",
        "    model.add(BatchNormalization())\n",
        "    model.add(MaxPooling2D(pool_size = (2, 2)))\n",
        "    model.add(GlobalAveragePooling2D())\n",
        "    model.add(Dense(288, activation = 'relu'))\n",
        "    model.add(Dense(288, activation = 'relu'))\n",
        "    model.add(BatchNormalization())\n",
        "    model.add(Dense(model_output_size, activation = 'softmax'))\n",
        "\n",
        "    model.summary()  #Show model summary\n",
        "\n",
        "    return model\n",
        "\n",
        "\n",
        "model = create_model()\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LcRo00mESMkC"
      },
      "source": [
        "plot_model(model,show_shapes = True, show_layer_names = True)  #Plot model diagram"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5mzN21eaSVce"
      },
      "source": [
        "from keras import optimizers\n",
        "import keras\n",
        "optimizer = keras.optimizers.Adam(lr=0.0001)\n",
        "\n",
        "early_stopping_callback = EarlyStopping(monitor = 'val_loss', patience = 10, mode = 'min', restore_best_weights = True) #Early stopping on patience 10\n",
        "\n",
        "\n",
        "model.compile(loss = 'categorical_crossentropy', optimizer = optimizer, metrics = [\"accuracy\"]) #Choose optimizer, loss and metrics\n",
        "\n",
        "model_training_history = model.fit(x = features_train, y = labels_train, epochs = 40, batch_size = 16 , shuffle = True, validation_split = 0.2, callbacks = [early_stopping_callback])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2RATuIJ0c92P"
      },
      "source": [
        "model_evaluation_history = model.evaluate(features_test, labels_test)\n",
        "\n",
        "from sklearn.metrics import classification_report\n",
        "\n",
        "y_pred = model.predict(features_test, batch_size=4, verbose=1)\n",
        "y_pred_bool = np.argmax(y_pred, axis=1)\n",
        "\n",
        "l_test=np.argmax(labels_test, axis=1)\n",
        "\n",
        "print(classification_report(l_test, y_pred_bool))\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3yftlPlQup5S"
      },
      "source": [
        "from sklearn.metrics import confusion_matrix\n",
        "cm = confusion_matrix(l_test, y_pred_bool)\n",
        "\n",
        "print (cm)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qQGd8maTdDR4"
      },
      "source": [
        "# Creating a useful name for our model, incase you're saving multiple models (OPTIONAL)\n",
        "date_time_format = '%Y_%m_%d__%H_%M_%S'\n",
        "current_date_time_dt = dt.datetime.now()\n",
        "current_date_time_string = dt.datetime.strftime(current_date_time_dt, date_time_format)\n",
        "model_evaluation_loss, model_evaluation_accuracy = model_evaluation_history\n",
        "model_name = f'Model___Date_Time_{current_date_time_string}___Loss_{model_evaluation_loss}___Accuracy_{model_evaluation_accuracy}.h5'\n",
        "\n",
        "# Saving your Model\n",
        "model.save(model_name)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mrGn8GWCdJgO"
      },
      "source": [
        "def plot_metric(metric_name_1, metric_name_2, plot_name):\n",
        "  # Get Metric values using metric names as identifiers\n",
        "  metric_value_1 = model_training_history.history[metric_name_1]\n",
        "  metric_value_2 = model_training_history.history[metric_name_2]\n",
        "\n",
        "  # Constructing a range object which will be used as time \n",
        "  epochs = range(len(metric_value_1))\n",
        "  \n",
        "  # Plotting the Graph\n",
        "  plt.plot(epochs, metric_value_1, 'blue', label = metric_name_1)\n",
        "  plt.plot(epochs, metric_value_2, 'red', label = metric_name_2)\n",
        "  \n",
        "  # Adding title to the plot\n",
        "  plt.title(str(plot_name))\n",
        "\n",
        "  # Adding legend to the plot\n",
        "  plt.legend()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Qjm_YZK0dSTr"
      },
      "source": [
        "plot_metric('loss', 'val_loss', 'Total Loss vs Total Validation Loss')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PA0TqPyedZop"
      },
      "source": [
        "plot_metric('accuracy', 'val_accuracy', 'Total Accuracy vs Total Validation Accuracy')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kdFwsUATQG6l"
      },
      "source": [
        "from collections import Counter\n",
        "\n",
        "def get_first_mode(a):\n",
        "    c = Counter(a)  \n",
        "    mode_count = max(c.values())\n",
        "    mode = {key for key, count in c.items() if count == mode_count}\n",
        "    first_mode = next(x for x in a if x in mode)\n",
        "    return first_mode"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ndIiTxzEz1UL"
      },
      "source": [
        "def frames_extraction2(video_path):\n",
        "    frames_list = []\n",
        "    \n",
        "    vidObj = cv2.VideoCapture(video_path)\n",
        "    \n",
        "  \n",
        "\n",
        "\n",
        "    # Used as counter variable \n",
        "    count = 0\n",
        " \n",
        "    while True: \n",
        "         \n",
        "        success, image = vidObj.read() \n",
        "\n",
        "        if success == False:\n",
        "          print(\"Defected frame\")\n",
        "          break\n",
        "\n",
        "        if count == 0:\n",
        "            image = cv2.resize(image, (image_height, image_width))\n",
        "            normalized_image = image / 255\n",
        "            frames_list.append(normalized_image)\n",
        "        \n",
        "        else:\n",
        "          if count % 25 == 0:\n",
        "            image = cv2.resize(image, (image_height, image_width))\n",
        "            normalized_image = image / 255\n",
        "            frames_list.append(normalized_image)\n",
        "        \n",
        "        count += 1\n",
        "            \n",
        "       \n",
        "            \n",
        "    return frames_list"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "stxAssUYihsG"
      },
      "source": [
        "#Evaluating a different dataset\n",
        "\n",
        "from tqdm import tqdm\n",
        "from statistics import mode\n",
        "\n",
        "\n",
        "predict = []\n",
        "actual = []\n",
        "dataset_directory2=\"UCF50\"\n",
        "\n",
        "# Declaring Empty Lists to store the features and labels values.\n",
        "temp_features = [] \n",
        "features = []\n",
        "labels = []\n",
        "\n",
        "cc=0\n",
        "\n",
        "# Iterating through all the classes mentioned in the classes list\n",
        "for class_index, class_name in enumerate(classes_list):\n",
        "    print(f'Extracting Data of Class: {class_name}')\n",
        "    \n",
        "    # Getting the list of video files present in the specific class name directory\n",
        "    files_list = os.listdir(os.path.join(dataset_directory2, class_name))\n",
        "\n",
        "    # Iterating through all the files present in the files list\n",
        "    for file_name in files_list:\n",
        "\n",
        "        # Construct the complete video path\n",
        "        video_file_path = os.path.join(dataset_directory2, class_name, file_name)\n",
        "\n",
        "        # Calling the frame_extraction method for every video file path\n",
        "        frames = frames_extraction2(video_file_path)\n",
        "\n",
        "        temppred=[]\n",
        "\n",
        "        for i in frames:\n",
        "          temppred.append(model.predict_classes(np.expand_dims(i, axis = 0))[0])\n",
        "        \n",
        "        print (temppred)\n",
        "        print (\"mode\", get_first_mode(temppred), cc)\n",
        "        cc+=1\n",
        "        predict.append(get_first_mode(temppred))\n",
        "        actual.append(class_index)\n",
        "\n",
        "\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jL3BiR2NyrRg"
      },
      "source": [
        "print(classification_report(actual, predict))\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UB3Cmhztzj4K"
      },
      "source": [
        "print(confusion_matrix(actual, predict))"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}